# -*- coding: utf-8 -*-
"""CNNfunctions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nzBfu3POVXHhoRzRreuemvRfLTe1qxiI
"""

# Import toolboxes

import tensorflow as tf
import matplotlib.pyplot as plt
import random as rnd
import numpy as np
import scipy.signal as sig
from scipy.io import loadmat
import math
import time

from scipy.io import loadmat
from tensorflow.keras.layers import Input, Conv1D, add, Activation
from tensorflow.keras.models import Model
from tensorflow.keras import initializers
from tensorflow.signal import fft, hann_window, stft

# Coherence function

def Coherence(x, y, window_length, sampling_frequency):

  x = np.transpose(x)
  y = np.transpose(y)

  faxis, Syx = sig.csd(x, y, fs=sampling_frequency, window='hann', nperseg=window_length, noverlap=window_length/2)
  faxis, Sxx = sig.csd(x, x, fs=sampling_frequency, window='hann', nperseg=window_length, noverlap=window_length/2)
  faxis, Syy = sig.csd(y, y, fs=sampling_frequency, window='hann', nperseg=window_length, noverlap=window_length/2)

  Cyx = np.abs(Syx)**2 / (Sxx*Syy)
  faxis = np.reshape(faxis, (Syx.shape))

  return Cyx, faxis

# Plot coherence function

def PlotCoherence(faxis, Cyx, xlim, legend):

  plt.plot(np.transpose(faxis), np.transpose(Cyx), linewidth=2)
  plt.xlim(xlim)
  plt.ylim((0,1))
  plt.xscale('log')
  plt.xlabel('Frequency (Hz)')
  plt.ylabel('Coherence')
  plt.grid()

  if len(legend) > 0:
    plt.legend(legend, loc='lower left')

  plt.show()

# Get train and test frames

# def LoadData(file_numbers, stem, receptive_field):

#   for f in range(len(file_numbers)):

#     filepath = '%(stem)s%(file_number)i.mat' % {"stem": stem, "file_number": file_numbers[f]}
#     data = loadmat(filepath)

#     y = data['F']
#     x = data['a']

#     if f == 0:
#       inputs = x[np.newaxis,:,:]
#       outputs = y[np.newaxis,receptive_field-1:,0]

#     else:
#       inputs = np.concatenate((inputs, x[np.newaxis,:,:]), axis=0)
#       outputs = np.concatenate((outputs, y[np.newaxis,receptive_field-1:,0]), axis=0)

#   inputs = tf.constant(inputs, dtype='float32')
#   outputs = tf.constant(outputs, dtype='float32')

#   return inputs, outputs

# Build a model

def l(Hpar):

  # Extract parameters from Hpar dictionary
  layers = Hpar['layers']
  skips = Hpar['skips']
  activation = Hpar['activation']
  channels = Hpar['channels']
  input_shape = Hpar['input_shape']
  receptive_field = Hpar['receptive_field']

  inputs = Input(shape=input_shape)
  h = inputs

  initializer = tf.keras.initializers.HeUniform()

  if skips == 0:

    for l in range(layers-1):

      dilation_rate = Hpar['kernel_width']**l
      h = Conv1D(channels[l], kernel_size=Hpar['kernel_width'], padding='valid', activation=activation,
                 dilation_rate=dilation_rate, kernel_initializer=initializer, use_bias=False)(h)

  elif skips == 1:

    n_skip_units, last_layer = divmod(layers-1, 2)
    
    for l in range(n_skip_units):

      g = Conv1D(channels[2*l], kernel_size=Hpar['kernel_width'], padding='valid', activation=activation, 
                 dilation_rate=Hpar['kernel_width']**(2*l), kernel_initializer=initializer, use_bias=True)(h)

      h = add([Conv1D(channels[2*l+1], kernel_size=Hpar['kernel_width'], padding='valid', activation=None, 
                 dilation_rate=Hpar['kernel_width']**(2*l+1), kernel_initializer=initializer, use_bias=True)(g),
          Conv1D(channels[2*l+1], kernel_size=Hpar['kernel_width']**2, padding='valid', activation=None, 
                 dilation_rate=Hpar['kernel_width']**(2*l), kernel_initializer=initializer, use_bias=False)(h)])
      
      h = Activation(activation=activation)(h)

    if last_layer == 1:

      h = Conv1D(channels[-1], kernel_size=Hpar['kernel_width'], padding='valid', activation=activation,
                 dilation_rate=Hpar['kernel_width']**(layers-1), kernel_initializer=initializer, use_bias=True)(h)


  elif skips == 2:

    n_skip_repeats, last_layer = divmod(layers-1, 2)
    n_skip_units, last_repeat_layer = divmod(n_skip_repeats, 2)

    receptive_field = Hpar['kernel_width']**(n_skip_repeats+1)

    if last_layer == 1:

      print('Error: if skips == 2 use an odd number of layers')
      return

    for k in range(2):

      for l in range(n_skip_units):

        g = Conv1D(channels[2*l+k*n_skip_repeats], kernel_size=Hpar['kernel_width'], padding='valid', activation=activation, 
                   dilation_rate=Hpar['kernel_width']**(2*l), kernel_initializer=initializer)(h)

        h = add([Conv1D(channels[2*l+k*n_skip_repeats+1], kernel_size=Hpar['kernel_width'], padding='valid', activation=None, 
                 dilation_rate=Hpar['kernel_width']**(2*l+1), kernel_initializer=initializer)(g),
            Conv1D(channels[2*l+k*n_skip_repeats+1], kernel_size=Hpar['kernel_width']**2, padding='valid', activation=None, 
                 dilation_rate=Hpar['kernel_width']**(2*l), kernel_initializer=initializer, use_bias=False)(h)])
        
        h = Activation(activation=activation)(h)

      if last_repeat_layer == 1:

        h = Conv1D(channels[(k+1)*n_skip_repeats-1], kernel_size=Hpar['kernel_width'], padding='valid', activation=activation,
                 dilation_rate=Hpar['kernel_width']**(n_skip_repeats-1), kernel_initializer=initializer)(h)

    if last_layer == 1:

      h = Conv1D(channels[-1], kernel_size=Hpar['kernel_width'], padding='valid', activation=activation,
                 dilation_rate=Hpar['kernel_width']**len(layers), kernel_initializer=initializer)(h)

  outputs = Conv1D(1, 1, kernel_initializer=initializer, use_bias=True)(h)

  model = Model(inputs=inputs, outputs=outputs)

  model.summary()
  
  return model

def CoherenceLoss(model, x, y, Opt):

  # Extract parameters from Opt dictionary
  freq_ind = Opt['freq_ind']
  window_length = Opt['window_length']

  # Calculate model prediction for current frame(s)
  ypred = model(x)

  # Calculate stft of y and ypred
  Y = stft(y,frame_length=window_length,frame_step=int(window_length/2),window_fn=tf.signal.hann_window)
  Ypred = stft(ypred[:,:,0],frame_length=window_length,frame_step=int(window_length/2),window_fn=tf.signal.hann_window)

  # Calculate average spectra over all batches
  Syy = tf.reduce_sum(Y * tf.math.conj(Y), axis=[0,1])
  Spp = tf.reduce_sum(Ypred * tf.math.conj(Ypred), axis=[0,1])
  Spy = tf.reduce_sum(Ypred * tf.math.conj(Y), axis=[0,1])

  # Calculate coherence
  Cpy = tf.math.square(tf.math.abs(Spy)) / tf.cast(Spp*Syy,tf.float32)
  Cpy_avg = tf.reduce_mean(Cpy[freq_ind[0]:freq_ind[1]])

  # Penalise positive phase in Spy to ensure causality
  #positive_phase = tf.nn.relu(tf.math.angle(Spy))
  #positive_phase = tf.math.angle(Spy) + tf.constant(math.pi)
  #sum_positive_phase = tf.reduce_sum(positive_phase)

  # Calculate loss
  # loss = tf.reduce_sum(1-Cpy[freq_ind[0]:freq_ind[1]])# + Opt['causality']*sum_positive_phase
  
  # Loss as vector
  loss = 1-Cpy[freq_ind[0]:freq_ind[1]]# + Opt['causality']*sum_positive_phase


  # Calculate transfer function
  Tpy = Spy/Spp

  return loss, Cpy_avg, Cpy, Tpy

# Define grad function

@tf.function
def grad(model, inputs, targets, Opt):
  with tf.GradientTape() as tape:
    loss, Cpy_avg, Cpy, Tpy = CoherenceLoss(model, inputs, targets, Opt)
  return loss, tape.gradient(loss, model.trainable_variables), Cpy_avg

# Define training loop

def TrainModel(model, optimizer, train_dataset,val_dataset, Opt, n_samples, model_save_path):

  start_time = time.time()

  best_loss = 1e5

  n_batches = np.ceil(n_samples/Opt['batch_size'])
  
  # Keeping results 
  train_loss_results = []
  train_Cpy_results = []
  val_loss_results = []
  val_Cpy_results = []

  for epoch in range(Opt['num_epochs']):

    # Shuffle data sets and arrange into batches
    shuffled_train_dataset = train_dataset.shuffle(n_samples, reshuffle_each_iteration=True)
    batched_train_dataset = shuffled_train_dataset.batch(batch_size=Opt['batch_size'])
    
    shuffled_val_dataset = val_dataset.shuffle(n_samples, reshuffle_each_iteration=True)
    batched_val_dataset = shuffled_val_dataset.batch(batch_size=Opt['batch_size'])
    
    epoch_train_loss = tf.keras.metrics.Mean()
    epoch_train_Cpy = tf.keras.metrics.Mean()
    epoch_val_loss = tf.keras.metrics.Mean()
    epoch_val_Cpy = tf.keras.metrics.Mean()

    # Iterate over batches
    for element in batched_train_dataset:

      # train_inputs = element[0];   train_outputs = element[1]
      loss, grads, Cpy_avg = grad(model, element[0], element[1], Opt)
      optimizer.apply_gradients(zip(grads, model.trainable_variables))
      
      epoch_train_loss(loss)
      epoch_train_Cpy(Cpy_avg)
    
    epoch_train_loss = epoch_train_loss.result()
    epoch_train_Cpy = epoch_train_Cpy.result()
    
    train_loss_results.append(epoch_train_loss)
    train_Cpy_results.append(epoch_train_Cpy)
    
    # Iterate over batches in validation set
    for element in batched_val_dataset:
        loss, Cpy_avg, Cpy, Tpy = CoherenceLoss(model, element[0], element[1], Opt)
        epoch_val_loss(loss)
        epoch_val_Cpy(Cpy_avg)
    
    epoch_val_loss = epoch_val_loss.result()
    epoch_val_Cpy = epoch_val_Cpy.result()
    
    val_loss_results.append(epoch_val_loss)
    val_Cpy_results.append(epoch_val_Cpy)

    print('Epoch {:03d}: Loss: {:.3f}, Cpy_avg: {:.3f}, Val Loss: {:.3f}, Val Cpy_avg: {:.3f}'.format(epoch, epoch_train_loss, epoch_train_Cpy, 
    epoch_val_loss, epoch_val_Cpy))
    
    # print('Epoch {:03d}: Loss: {:.3f}, Cpy_avg: {:.3f}'.format(epoch, epoch_train_loss, epoch_train_Cpy))
    
    if epoch_train_loss < best_loss:
        best_loss = epoch_train_loss
        model.save(model_save_path)
        print(f'Epoch loss improved to {epoch_train_loss:.3f}. Saving model. ')
    
  print("Duration :{:.3f}".format(time.time() - start_time))
  
  return (train_loss_results, train_Cpy_results) #, val_loss_results, val_Cpy_results)

## NOT USED IN MODEL
# Split time series into odd frames

def SplitIntoFrames(file_numbers, stem, receptive_field, window_length, n_channels):

  P = 0

  for f in range(len(file_numbers)):

    filepath = '%(stem)s%(file_number)i.mat' % {"stem": stem, "file_number": file_numbers[f]}
    data = loadmat(filepath)

    y = data['F']
    x = data['a']

    n_odd_frames = math.floor((len(y)-receptive_field+1) / window_length)

    input_frames = np.zeros((n_odd_frames*len(file_numbers), window_length + receptive_field - 1, n_channels))
    output_frames = np.zeros((n_odd_frames*len(file_numbers), window_length, n_channels))


    for p in range(n_odd_frames):

      output_ind = range(p*window_length + receptive_field - 1, (p+1)*window_length + receptive_field - 1)
      input_ind = range(p*window_length, (p+1)*window_length + receptive_field - 1)

      input_frames[p+P,:,:] = x[input_ind]
      output_frames[p+P,:,:] = y[output_ind]

    P = P + n_odd_frames

  return input_frames, output_frames

## NOT USED IN MODEL
# Define loss function with coherence calculated one frame at a time

def CoherenceLoss_frames(model, x, Y, spy, spp, syy):

  k1 = 3
  k2 = 300

  # Calculate model prediction for current frame(s)
  ypred = model(x)

  # Apply window function to predicted frames
  window = hann_window(window_length)
  ypred_windowed = window[np.newaxis,:,np.newaxis] * ypred
  ypred = tf.cast(ypred_windowed, dtype='complex64')

  # Transpose and take ffts
  ypred_transpose = tf.transpose(ypred, perm=[1,0,2])
  Ypred_transpose = fft(ypred_transpose)
  Ypred =  tf.transpose(Ypred_transpose, perm=[1,0,2])

  # Calculate spectra
  Spp = tf.math.reduce_sum(Ypred * tf.math.conj(Ypred), axis=0, keepdims=True)
  Spy = tf.math.reduce_sum(Ypred * tf.math.conj(Y), axis=0, keepdims=True)
  Syy = tf.math.reduce_sum(Y * tf.math.conj(Y), axis=0, keepdims=True)

  # Add to spectra dictionary
  #new_spectra = spectra
  #new_spectra['spp'] = new_spectra['spp'] + tf.cast(Spp, dtype='float32')
  #new_spectra['spy'] = new_spectra['spy'] + Spy
  #new_spectra['syy'] = new_spectra['syy'] + tf.cast(Syy, dtype='float32')

  Spp_n = tf.cast(Spp, dtype='float32') + spp
  Spy_n = Spy + spy
  Syy_n = tf.cast(Syy, dtype='float32') + syy

  # Calculate coherence
  #Cpy = tf.math.square(tf.math.abs(new_spectra['spy'])) / (new_spectra['spp']*new_spectra['syy'])
  Cpy = tf.math.square(tf.math.abs(Spy_n)) / (Spp_n*Syy_n + 1e-12)
  #Cpy_avg = tf.math.reduce_mean(tf.slice(Cpy, [0,k1,0], [0,k2-k1,0]), keepdims=True)

  Cpy_slice = tf.slice(Cpy, [0,k1,0], [1,k2-k1,1])
  Cpy_avg = tf.math.reduce_mean(Cpy_slice[0,:,0], keepdims=True)

  # Calculate sum of 1 - Cpy
  Loss = tf.math.reduce_sum(tf.slice(1-Cpy, [0,k1,0], [1,k2-k1,1]), keepdims=False)
  #Loss = tf.math.reduce_sum(1-Cpy[0,k1:k2,0], keepdims=True)
  #print( tf.math.reduce_sum(1-Cpy[0,k1:k2,0], keepdims=True))

  # Save new spectra
  new_spectra = {'spy': Spy_n,
                 'syy': Syy_n,
                 'spp': Spp_n,
                 'cpy': Cpy}

  return Loss, new_spectra, Cpy_avg

## NOT USED IN MODEL
# Gradient function for frame cost function

# Define grad function

@tf.function
def grad_frames(model, inputs, targets, spectra):
  with tf.GradientTape() as tape:
    loss, new_spectra, Cpy_avg = CoherenceLoss_frames(model, inputs, targets, spectra['spy'], spectra['spp'], spectra['syy'])
  return loss, tape.gradient(loss, model.trainable_variables), new_spectra, Cpy_avg
  
